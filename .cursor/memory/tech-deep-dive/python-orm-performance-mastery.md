# üêç Python/Odoo ORM Performance - Mastery Guide

> **Odoo ORM Optimization** - T√©cnicas avan√ßadas de performance para Python e ORM do Odoo
>
> **√öltima atualiza√ß√£o:** 2025-11-17
> **Vers√£o Odoo:** 15.0+ (aplic√°vel at√© 18.0)
> **Status:** ‚úÖ Conhecimento Consolidado

---

## üìö √çndice

1. [ORM Fundamentals](#orm-fundamentals)
2. [N+1 Query Problem](#n1-query-problem)
3. [search_fetch() Optimization](#search_fetch-optimization)
4. [Computed Fields Performance](#computed-fields-performance)
5. [Prefetching Mechanism](#prefetching-mechanism)
6. [SQL Direct Queries](#sql-direct-queries)
7. [Batch Operations](#batch-operations)
8. [Caching Strategies](#caching-strategies)
9. [Best Practices](#best-practices)

---

## üéØ ORM Fundamentals

### ORM Architecture

```python
# Odoo ORM Layers
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Python Business Logic         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Odoo ORM (models.py)          ‚îÇ  ‚Üê Active Record Pattern
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   psycopg2 (PostgreSQL driver)  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   PostgreSQL Database           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Basic ORM Operations

```python
# Environment and Context
env = self.env  # Current environment
model = env['res.partner']  # Get model

# CRUD Operations
record = model.create({'name': 'John'})  # INSERT
records = model.search([('name', '=', 'John')])  # SELECT WHERE
record.write({'email': 'john@example.com'})  # UPDATE
record.unlink()  # DELETE

# Search variations
all_partners = model.search([])  # All records
active_partners = model.search([('active', '=', True)])
limited = model.search([], limit=10)
ordered = model.search([], order='name ASC')
count = model.search_count([('is_company', '=', True)])

# Read operations
data = records.read(['name', 'email'])  # SELECT specific fields
ids = records.ids  # List of IDs
names = records.mapped('name')  # Extract field values
```

---

## ‚ö†Ô∏è N+1 Query Problem

### The Problem

```python
# ‚ùå RUIM: N+1 queries (1 query + N queries)
leads = self.env['crm.lead'].search([('state', '=', 'new')])  # 1 query
for lead in leads:  # N iterations
    partner_name = lead.partner_id.name  # N queries! (1 per lead)
    partner_phone = lead.partner_id.phone  # N more queries!
    print(f"{partner_name}: {partner_phone}")

# Result: 1 + 100*2 = 201 queries for 100 leads!
```

**Performance Impact:**
- 100 leads = 201 queries
- Each query ~5ms = 1000ms (1 second)
- Database connection overhead
- Network latency

### Solution 1: Proper @api.depends

```python
from odoo import models, fields, api

class CrmLead(models.Model):
    _inherit = 'crm.lead'

    # ‚ùå RUIM: Depends sem campo espec√≠fico
    partner_phone = fields.Char(compute='_compute_partner_phone')

    @api.depends('partner_id')  # ‚Üê N√£o especifica qual campo!
    def _compute_partner_phone(self):
        for record in self:
            record.partner_phone = record.partner_id.phone  # N+1!

    # ‚úÖ BOM: Depends com campo completo
    partner_phone = fields.Char(compute='_compute_partner_phone')

    @api.depends('partner_id.phone')  # ‚Üê Especifica campo exato!
    def _compute_partner_phone(self):
        for record in self:
            record.partner_phone = record.partner_id.phone  # Cached! 1 query

    # ‚úÖ MELHOR: Store para campos muito acessados
    partner_phone = fields.Char(
        compute='_compute_partner_phone',
        store=True  # ‚Üê Salvo no banco! 0 queries ao ler
    )

    @api.depends('partner_id.phone')
    def _compute_partner_phone(self):
        for record in self:
            record.partner_phone = record.partner_id.phone
```

**Performance:**
- Sem store: 100 leads = 2 queries (1 lead + 1 partners batch)
- Com store: 100 leads = 1 query (direto do banco)
- **Melhoria: 100x mais r√°pido!**

### Solution 2: Prefetch with mapped()

```python
# ‚ùå RUIM: Iterar sem prefetch
for lead in leads:
    print(lead.partner_id.name)  # N queries

# ‚úÖ BOM: Prefetch com mapped()
partners = leads.mapped('partner_id')  # 1 query - fetch all partners
for lead in leads:
    print(lead.partner_id.name)  # 0 additional queries (cached)

# ‚úÖ MELHOR: Processar valores diretamente
partner_names = leads.mapped('partner_id.name')  # 1 query
for name in partner_names:
    print(name)
```

### Solution 3: Use read()

```python
# ‚úÖ BOM: read() √© otimizado
data = leads.read(['name', 'partner_id', 'stage_id'])
# Returns: [{'id': 1, 'name': 'Lead 1', 'partner_id': (5, 'John'), 'stage_id': (2, 'New')}, ...]

# Process data without additional queries
for item in data:
    print(f"{item['name']} - Partner: {item['partner_id'][1]}")
```

---

## üöÄ search_fetch() Optimization

### Odoo 17.4+ Only

```python
# ‚ùå ANTES (Odoo ‚â§17.3): 2 queries
leads = self.env['crm.lead'].search([('state', '=', 'new')])  # Query 1
data = leads.read(['name', 'partner_id', 'expected_revenue'])  # Query 2

# ‚úÖ DEPOIS (Odoo 17.4+): 1 query
data = self.env['crm.lead'].search_fetch(
    [('state', '=', 'new')],  # Domain
    ['name', 'partner_id', 'expected_revenue']  # Fields
)

# Retorna lista de dicion√°rios (mesmo que read())
# Performance: 30% mais r√°pido!
```

**Benef√≠cios:**
- ‚úÖ 1 query ao inv√©s de 2
- ‚úÖ Menos overhead de processamento
- ‚úÖ 30% redu√ß√£o de tempo
- ‚úÖ Compat√≠vel com limit, offset, order

**Limita√ß√£o:**
- ‚ö†Ô∏è Dispon√≠vel APENAS em Odoo 17.4+
- ‚ö†Ô∏è Nosso projeto (Odoo 15) N√ÉO tem search_fetch()

---

## üíæ Computed Fields Performance

### Store vs Non-Store

```python
class ProductProduct(models.Model):
    _inherit = 'product.product'

    # ‚ùå RUIM: Sem store, calculado sempre
    total_stock = fields.Float(
        compute='_compute_total_stock'
    )

    @api.depends('stock_quant_ids.quantity')
    def _compute_total_stock(self):
        for product in self:
            # Query pesada a cada acesso!
            product.total_stock = sum(product.stock_quant_ids.mapped('quantity'))

    # ‚úÖ BOM: Com store, calculado 1x
    total_stock = fields.Float(
        compute='_compute_total_stock',
        store=True  # ‚Üê Salvo no banco
    )

    @api.depends('stock_quant_ids.quantity')
    def _compute_total_stock(self):
        for product in self:
            # Executa apenas quando depend√™ncias mudam
            product.total_stock = sum(product.stock_quant_ids.mapped('quantity'))
```

**Quando usar store=True:**
- ‚úÖ Campo acessado frequentemente (listagens, relat√≥rios)
- ‚úÖ C√°lculo custoso (queries, loops, agrega√ß√µes)
- ‚úÖ Depend√™ncias n√£o mudam com frequ√™ncia
- ‚úÖ Espa√ßo em disco n√£o √© problema

**Quando N√ÉO usar store:**
- ‚ùå Campo raramente acessado
- ‚ùå C√°lculo trivial (concatena√ß√£o strings)
- ‚ùå Depend√™ncias mudam constantemente
- ‚ùå Dados sens√≠veis ao tempo (datetime.now())

**Performance Impact:**
| Scenario | Without store | With store | Improvement |
|----------|---------------|------------|-------------|
| List 100 products | 100 queries | 0 queries | ‚àû |
| Read 1 product | 1 query | 0 queries | - |
| Report 1000+ | 1000+ queries | 0 queries | **100x faster** |

---

## üîÑ Prefetching Mechanism

### How Prefetching Works

```python
# Odoo ORM Prefetch Autom√°tico
leads = self.env['crm.lead'].search([], limit=100)

# Primeiro acesso a um campo
first_lead = leads[0]
name = first_lead.name  # ‚Üê Trigger: ORM fetches 'name' for ALL 100 leads!

# Acessos subsequentes
for lead in leads:
    print(lead.name)  # 0 queries - all cached!
```

**Prefetch Size:** Default 1000 records

### Controlling Prefetch

```python
# Disable prefetch (raramente necess√°rio)
leads = self.env['crm.lead'].with_context(prefetch_fields=False).search([])

# Custom prefetch size
leads = self.env['crm.lead'].with_context(prefetch={'limit': 500}).search([])
```

### Prefetch with Related Fields

```python
# ‚úÖ BOM: Prefetch de campos relacionados
leads = self.env['crm.lead'].search([])

# Trigger prefetch de partners
_ = leads.mapped('partner_id')

# Agora todos os acessos s√£o cached
for lead in leads:
    print(lead.partner_id.name)  # 0 queries
    print(lead.partner_id.email)  # 0 queries
```

---

## üíª SQL Direct Queries

### When to Use SQL

Use SQL direto quando:
- ‚úÖ Agrega√ß√µes complexas (SUM, AVG, GROUP BY)
- ‚úÖ Joins complexos (3+ tabelas)
- ‚úÖ Performance cr√≠tica (relat√≥rios, dashboards)
- ‚úÖ Bulk operations (milhares de registros)

**N√ÉO use SQL para:**
- ‚ùå CRUD simples (use ORM)
- ‚ùå Quando ORM √© suficiente
- ‚ùå L√≥gica de neg√≥cio complexa

### SQL Queries Safely

```python
from odoo import models, api

class ReportSales(models.Model):
    _name = 'report.sales'

    def get_sales_statistics(self, date_from, date_to):
        """Estat√≠sticas de vendas por vendedor."""

        # ‚úÖ SEGURO: Use %s para par√¢metros
        query = """
            SELECT
                ru.name as seller_name,
                COUNT(so.id) as order_count,
                SUM(so.amount_total) as total_amount,
                AVG(so.amount_total) as avg_amount
            FROM sale_order so
            JOIN res_users ru ON so.user_id = ru.id
            WHERE so.state = 'sale'
              AND so.date_order >= %s
              AND so.date_order <= %s
            GROUP BY ru.id, ru.name
            ORDER BY total_amount DESC
        """

        # Execute com par√¢metros
        self.env.cr.execute(query, (date_from, date_to))

        # Fetch results
        results = self.env.cr.dictfetchall()
        # Returns: [{'seller_name': 'John', 'order_count': 10, 'total_amount': 5000, ...}, ...]

        return results

    def bulk_update_prices(self, product_ids, discount_percent):
        """Atualiza√ß√£o em massa de pre√ßos."""

        # ‚ùå NUNCA: String formatting (SQL INJECTION!)
        # query = f"UPDATE product_product SET list_price = list_price * {discount_percent} WHERE id IN {tuple(product_ids)}"

        # ‚úÖ SEGURO: Par√¢metros
        query = """
            UPDATE product_product
            SET list_price = list_price * %s
            WHERE id = ANY(%s)
        """
        self.env.cr.execute(query, (discount_percent, product_ids))

        # ‚ö†Ô∏è IMPORTANTE: Invalidar cache!
        self.env['product.product'].invalidate_cache(['list_price'], product_ids)
```

### SQL Performance Tips

```python
# 1. Use EXPLAIN ANALYZE para debug
self.env.cr.execute("EXPLAIN ANALYZE SELECT ...")
plan = self.env.cr.fetchall()
print(plan)

# 2. Use √≠ndices apropriados (ver postgresql-mastery.md)

# 3. Limit results
query = "SELECT * FROM sale_order LIMIT 1000"  # Sempre use LIMIT!

# 4. Use prepared statements (psycopg2 faz automaticamente com %s)
```

---

## üì¶ Batch Operations

### create_multi (Odoo 13+)

```python
# ‚ùå RUIM: Criar 1 por 1
for i in range(1000):
    self.env['product.product'].create({'name': f'Product {i}'})
# Result: 1000 queries

# ‚úÖ BOM: Batch create
vals_list = [{'name': f'Product {i}'} for i in range(1000)]
self.env['product.product'].create(vals_list)
# Result: 1 query (com m√∫ltiplos INSERTs)
# Performance: 100x mais r√°pido!
```

### Batch Write

```python
# ‚ùå RUIM: Write 1 por 1
for product in products:
    product.write({'list_price': product.list_price * 1.1})
# Result: N queries

# ‚úÖ BOM: Batch write
products.write({'list_price': sql.SQL('list_price * 1.1')})
# Result: 1 query
```

### Batch Unlink

```python
# ‚ùå RUIM: Delete 1 por 1
for partner in old_partners:
    partner.unlink()

# ‚úÖ BOM: Batch delete
old_partners.unlink()
# Result: 1 query (DELETE WHERE id IN (...))
```

---

## üíæ Caching Strategies

### ORM Cache

```python
# Cache √© autom√°tico para campos j√° acessados
lead = self.env['crm.lead'].browse(123)
name = lead.name  # Query executada
name_again = lead.name  # Cache! 0 queries

# Invalidar cache manualmente
lead.invalidate_cache(['name'])
name_fresh = lead.name  # Query executada novamente
```

### @tools.ormcache Decorator

```python
from odoo import models, tools

class ProductProduct(models.Model):
    _inherit = 'product.product'

    @tools.ormcache('product_id')
    def get_stock_info(self, product_id):
        """Cached function - chamadas repetidas retornam cache."""
        product = self.browse(product_id)
        return {
            'qty': sum(product.stock_quant_ids.mapped('quantity')),
            'value': product.standard_price * qty
        }

    # Limpar cache quando necess√°rio
    def write(self, vals):
        result = super().write(vals)
        if 'standard_price' in vals:
            self.get_stock_info.clear_cache(self)
        return result
```

### Redis/Memcached (Externo)

```python
# Para caching avan√ßado (n√£o nativo do Odoo)
import redis

class MyModel(models.Model):
    _name = 'my.model'

    def get_expensive_data(self):
        cache_key = f'expensive_data_{self.id}'

        # Check Redis first
        redis_client = redis.Redis(host='localhost', port=6379)
        cached = redis_client.get(cache_key)

        if cached:
            return json.loads(cached)

        # Compute data
        data = self._compute_expensive_data()

        # Cache for 1 hour
        redis_client.setex(cache_key, 3600, json.dumps(data))

        return data
```

---

## üéØ Best Practices

### 1. Sempre Especificar Campos

```python
# ‚ùå RUIM: Fetch todos os campos
partners = self.env['res.partner'].search([])
data = partners.read()  # Fetch ALL fields (100+ fields!)

# ‚úÖ BOM: Fetch apenas necess√°rios
data = partners.read(['name', 'email', 'phone'])  # 3 fields only
```

### 2. Use Domain Filters

```python
# ‚ùå RUIM: Fetch all e filtrar em Python
all_leads = self.env['crm.lead'].search([])
new_leads = [l for l in all_leads if l.state == 'new']  # Filter in Python!

# ‚úÖ BOM: Filtrar no banco
new_leads = self.env['crm.lead'].search([('state', '=', 'new')])  # WHERE clause
```

### 3. Limit Large Datasets

```python
# ‚ùå RUIM: Fetch milh√µes de registros
all_logs = self.env['mail.message'].search([])  # OOM risk!

# ‚úÖ BOM: Use limit e pagination
page_size = 1000
offset = 0
while True:
    logs = self.env['mail.message'].search([], limit=page_size, offset=offset)
    if not logs:
        break
    process(logs)
    offset += page_size
```

### 4. Avoid Computed Fields in Loops

```python
# ‚ùå RUIM: Acessar computed em loop
for product in products:
    if product.qty_available > 0:  # Computed field - expensive!
        available_products.append(product)

# ‚úÖ BOM: Filter no banco com SQL ou stored computed
available_products = products.filtered(lambda p: p.qty_available > 0)
# Melhor ainda: Use domain search se campo √© stored
```

### 5. Use sudo() Wisely

```python
# ‚ö†Ô∏è CUIDADO: sudo() bypassa permiss√µes
partner = self.env['res.partner'].sudo().search([])  # Admin access!

# ‚úÖ BOM: Use apenas quando necess√°rio e validado
if self.env.user.has_group('base.group_system'):
    partner = self.env['res.partner'].sudo().create(vals)
```

---

## üìä Performance Checklist

**Antes de Fazer Deploy:**

- [ ] Todos campos computed frequentes t√™m `store=True`
- [ ] N+1 queries eliminados (verificar com pg_stat_statements)
- [ ] @api.depends especifica campos completos (ex: 'partner_id.name')
- [ ] Bulk operations usam create/write em batch
- [ ] SQL queries usam %s para par√¢metros (NUNCA f-strings!)
- [ ] Large datasets t√™m limit/pagination
- [ ] Computed fields n√£o s√£o chamados em loops
- [ ] Cache invalidado quando necess√°rio
- [ ] PostgreSQL indexes apropriados (ver postgresql-mastery.md)
- [ ] Tests de performance executados

---

## üîß Debugging Performance

### Enable SQL Logging

```python
# In odoo.conf or command line
# --log-sql
# --log-level=debug_sql

# Logs mostrar√£o todas as queries executadas
```

### pg_stat_statements

```sql
-- Habilitar no PostgreSQL
CREATE EXTENSION pg_stat_statements;

-- Ver queries mais lentas
SELECT
    calls,
    mean_exec_time,
    query
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 20;

-- Reset stats
SELECT pg_stat_statements_reset();
```

### Python Profiling

```python
import cProfile
import pstats

def profile_function():
    profiler = cProfile.Profile()
    profiler.enable()

    # Code to profile
    result = self.expensive_operation()

    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumtime')
    stats.print_stats(20)  # Top 20 slowest functions

    return result
```

---

## üìö Recursos

### Documenta√ß√£o Oficial
- **Odoo ORM:** https://www.odoo.com/documentation/17.0/developer/reference/backend/orm.html
- **Performance Guidelines:** https://www.odoo.com/documentation/17.0/developer/howtos/rdtraining/14_other_module_techniques.html#performance

### Ferramentas
- **pg_stat_statements:** PostgreSQL query statistics
- **Odoo Profiler:** Built-in profiler (enable with --dev=all)
- **Python cProfile:** Standard library profiling
- **py-spy:** Sampling profiler (no code changes needed)

---

## üí° Conclus√£o

**Otimiza√ß√µes essenciais:**
1. ‚úÖ Eliminate N+1 queries (@api.depends completo)
2. ‚úÖ Store computed fields frequentes (20-100x faster)
3. ‚úÖ Use batch operations (100x faster)
4. ‚úÖ Prefetch com mapped() (evita queries extras)
5. ‚úÖ SQL direto para agrega√ß√µes complexas

**Para nosso projeto (Odoo 15):**
- ‚ö†Ô∏è search_fetch() N√ÉO dispon√≠vel (Odoo 17.4+ only)
- ‚úÖ Todas outras t√©cnicas aplic√°veis
- üìä Foco em N+1 elimination e stored computed fields

---

**Criado:** 2025-11-17
**Fontes:** Odoo docs, OCA guidelines, experi√™ncia pr√°tica
**Status:** ‚úÖ Conhecimento Consolidado
**Aplica√ß√£o:** Imediata - Odoo 15 projeto atual
